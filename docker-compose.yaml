version: '2.3'

services:
  api:
    build:
      context: ./api
      dockerfile: Dockerfile
    ports:
      - "8080:8080"
    environment:
      PYTHONUNBUFFERED: 1
      REDIS_HOST: redis
      REDIS_PORT: 6379
      AWS_ACCESS_KEY: ${AWS_ACCESS_KEY}
      AWS_SECRET_KEY: ${AWS_SECRET_KEY}
      S3_BUCKET: ${S3_BUCKET}
      AWS_REGION: ${AWS_REGION}
      AWS_ENDPOINT_URL: http://localstack:4566
      MONGO_URI: mongodb://root:example@mongo:27017
      SEARCH_SERVICE_HOST: http://training-service:5000
    depends_on:
      - mongo
      - redis
      - training-service
    networks:
      - app-network

  ml-base:
    build:
      context: ./trainer
      dockerfile: Dockerfile.base
    image: ml-base:latest

  training-service:
    build:
      context: ./trainer
      dockerfile: Dockerfile.python
      args:
        PYTHON_VERSION: 3.9
        BUILD_TYPE: gpu
        PYTORCH_INDEX: "https://download.pytorch.org/whl/cu118"
        BASE_IMAGE: ml-base:latest
    image: training-service:latest
    environment:
      PYTHONUNBUFFERED: 1
      REDIS_HOST: redis
      REDIS_PORT: 6379
      AWS_ACCESS_KEY: ${AWS_ACCESS_KEY}
      AWS_SECRET_KEY: ${AWS_SECRET_KEY}
      S3_BUCKET: ${S3_BUCKET}
      AWS_REGION: ${AWS_REGION}
      AWS_ENDPOINT_URL: http://localstack:4566
      SERVICE_PORT: 5001
      TRAINING_QUEUE: training_queue
      MODEL_PREFIX: model_status
      NVIDIA_VISIBLE_DEVICES: all
      CUDA_VISIBLE_DEVICES: "0"
      TRANSFORMERS_CACHE: /app/cache/transformers
      HF_HOME: /app/cache/huggingface
      MODEL_CACHE_DIR: /app/cache/models
    ports:
      - "5001:5001"
    command: ["python", "training_service.py"]
    volumes:
      - ./cache:/app/cache
    depends_on:
      - redis
      - ml-base
    networks:
      - app-network
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    runtime: nvidia

  search-service:
    build:
      context: ./trainer
      dockerfile: Dockerfile.python
      args:
        PYTHON_VERSION: 3.9
        BUILD_TYPE: gpu
        PYTORCH_INDEX: "https://download.pytorch.org/whl/cu118"
        BASE_IMAGE: ml-base:latest
    image: search-service:latest
    environment:
      PYTHONUNBUFFERED: 1
      REDIS_HOST: redis
      REDIS_PORT: 6379
      AWS_ACCESS_KEY: ${AWS_ACCESS_KEY}
      AWS_SECRET_KEY: ${AWS_SECRET_KEY}
      S3_BUCKET: ${S3_BUCKET}
      AWS_REGION: ${AWS_REGION}
      AWS_ENDPOINT_URL: http://localstack:4566
      SERVICE_PORT: 5000
      TRANSFORMERS_CACHE: /app/cache/transformers
      HF_HOME: /app/cache/huggingface
      MODEL_CACHE_DIR: /app/cache/models
    ports:
      - "5000:5000"
    command: ["python", "search_service.py"]
    volumes:
      - ./cache:/app/cache
    depends_on:
      - redis
      - ml-base
    networks:
      - app-network
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    runtime: nvidia

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    command: redis-server --appendonly yes
    volumes:
      - redis_data:/data
    networks:
      - app-network

  mongo:
    image: mongo:latest
    ports:
      - "27017:27017"
    environment:
      MONGO_INITDB_ROOT_USERNAME: root
      MONGO_INITDB_ROOT_PASSWORD: example
    volumes:
      - mongodb_data:/data/db
    networks:
      - app-network

  localstack:
    image: localstack/localstack:latest
    ports:
      - "4566:4566"
    environment:
      - SERVICES=s3
      - AWS_DEFAULT_REGION=us-east-1
      - EDGE_PORT=4566
      - DEBUG=1
    volumes:
      - ./localstack:/var/lib/localstack
    networks:
      - app-network
  
  frontend:
    build:
      context: ./playground 
      dockerfile: Dockerfile
    ports:
      - "0.0.0.0:3000:3000"
    environment:
      - NEXT_PUBLIC_API_URL=http://api:8080
    networks:
      - app-network
    depends_on:
      - api
    profiles:
      - dev
networks:
  app-network:

volumes:
  mongodb_data:
  redis_data: